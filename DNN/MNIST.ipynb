{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "    x_test  = x_test.reshape(x_test.shape[0], -1)\n",
    "    x_train = x_train.astype('float32')\n",
    "    x_test  = x_test.astype('float32')\n",
    "    x_train = x_train / 255\n",
    "    x_test  = x_test / 255\n",
    "    \n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test  = np_utils.to_categorical(y_test, 10)\n",
    "    \n",
    "    return (x_train, y_train), (x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    # input layer\n",
    "    model.add(Dense(input_dim=28*28, units=392, activation='relu', kernel_initializer='he_normal', kernel_regularizer='l2'))\n",
    "    #  or use input_shape=(784,)\n",
    "\n",
    "    # hidden layer\n",
    "    model.add(Dense(units=196, activation='relu', kernel_initializer='he_normal', kernel_regularizer='l2'))\n",
    "    model.add(Dense(units=98, activation='relu', kernel_initializer='he_normal', kernel_regularizer='l2'))\n",
    "    model.add(Dense(units=49, activation='relu', kernel_initializer='he_normal', kernel_regularizer='l2'))\n",
    "    \n",
    "    # output layer\n",
    "    model.add(Dense(units=10, activation='softmax', kernel_initializer='he_normal', kernel_regularizer='l2'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 196)               77028     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 98)                19306     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 49)                4851      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                500       \n",
      "=================================================================\n",
      "Total params: 409,405\n",
      "Trainable params: 409,405\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 4s 76us/step - loss: 2.7695 - acc: 0.8667 - val_loss: 1.2319 - val_acc: 0.8935\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 1.0844 - acc: 0.9098 - val_loss: 0.9757 - val_acc: 0.9231\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.9688 - acc: 0.9142 - val_loss: 0.9080 - val_acc: 0.9294\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.9198 - acc: 0.9181 - val_loss: 0.8852 - val_acc: 0.9261\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8927 - acc: 0.9215 - val_loss: 0.8773 - val_acc: 0.9251\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8796 - acc: 0.9207 - val_loss: 0.8582 - val_acc: 0.9260\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8587 - acc: 0.9239 - val_loss: 0.8683 - val_acc: 0.9155\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8498 - acc: 0.9237 - val_loss: 0.8330 - val_acc: 0.9278\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.8415 - acc: 0.9240 - val_loss: 0.8230 - val_acc: 0.9318\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8337 - acc: 0.9275 - val_loss: 0.8298 - val_acc: 0.9300\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8301 - acc: 0.9279 - val_loss: 0.8073 - val_acc: 0.9383\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8302 - acc: 0.9281 - val_loss: 0.8322 - val_acc: 0.9228\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8199 - acc: 0.9291 - val_loss: 0.7977 - val_acc: 0.9373\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8156 - acc: 0.9300 - val_loss: 0.8047 - val_acc: 0.9361\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8118 - acc: 0.9311 - val_loss: 0.8130 - val_acc: 0.9291\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8111 - acc: 0.9311 - val_loss: 0.7858 - val_acc: 0.9392\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8099 - acc: 0.9314 - val_loss: 0.8003 - val_acc: 0.9353\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8069 - acc: 0.9309 - val_loss: 0.7893 - val_acc: 0.9376\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.8052 - acc: 0.9320 - val_loss: 0.7835 - val_acc: 0.9408\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.8081 - acc: 0.9306 - val_loss: 0.8381 - val_acc: 0.9182\n",
      "60000/60000 [==============================] - 5s 78us/step\n",
      "Train Acc: [0.8428776130994161, 0.9164166666666667]\n",
      "10000/10000 [==============================] - 1s 79us/step\n",
      "Test Acc: [0.8412266417503357, 0.9155]\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=128, epochs=20, validation_split=0.2)\n",
    "\n",
    "score = model.evaluate(x_train, y_train)\n",
    "print('Train Acc:', score)\n",
    "\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test Acc:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.8667083333333333,\n",
       "  0.9098125,\n",
       "  0.9142083333333333,\n",
       "  0.9181458333333333,\n",
       "  0.9214583333333334,\n",
       "  0.9206875,\n",
       "  0.9239375,\n",
       "  0.92375,\n",
       "  0.9239791666666667,\n",
       "  0.9275416666666667,\n",
       "  0.9279166666666666,\n",
       "  0.9280833333333334,\n",
       "  0.9291458333333333,\n",
       "  0.93,\n",
       "  0.9311041666666666,\n",
       "  0.9311458333333333,\n",
       "  0.9314166666666667,\n",
       "  0.9309166666666666,\n",
       "  0.9319791666666667,\n",
       "  0.9305833333333333],\n",
       " 'loss': [2.7695295674006144,\n",
       "  1.084434863726298,\n",
       "  0.9688359066645305,\n",
       "  0.9198218468030294,\n",
       "  0.8926662375132243,\n",
       "  0.8795640813509623,\n",
       "  0.8586762811342875,\n",
       "  0.8497799050013224,\n",
       "  0.8415126994450887,\n",
       "  0.8336903195381165,\n",
       "  0.830085991859436,\n",
       "  0.8301745462417602,\n",
       "  0.8198806765874227,\n",
       "  0.8155863647460937,\n",
       "  0.8118058778444925,\n",
       "  0.8111272498766581,\n",
       "  0.8098756446838379,\n",
       "  0.8069047740300497,\n",
       "  0.8051515302658081,\n",
       "  0.8080697374343873],\n",
       " 'val_acc': [0.8935000001589457,\n",
       "  0.9230833331743876,\n",
       "  0.9294166668256124,\n",
       "  0.9260833333333334,\n",
       "  0.925083333492279,\n",
       "  0.9260000001589457,\n",
       "  0.9154999998410542,\n",
       "  0.9277500001589457,\n",
       "  0.931833333492279,\n",
       "  0.9299999998410543,\n",
       "  0.9383333334922791,\n",
       "  0.9228333331743876,\n",
       "  0.93725,\n",
       "  0.936083333492279,\n",
       "  0.929083333492279,\n",
       "  0.9391666668256123,\n",
       "  0.9353333334922791,\n",
       "  0.9375833334922791,\n",
       "  0.9408333333333333,\n",
       "  0.9181666666666667],\n",
       " 'val_loss': [1.2319369331995647,\n",
       "  0.9756783088048299,\n",
       "  0.9079874544143677,\n",
       "  0.8852246160507202,\n",
       "  0.8772865436871846,\n",
       "  0.8582320456504822,\n",
       "  0.8683288243611653,\n",
       "  0.8329885546366373,\n",
       "  0.8230235765775045,\n",
       "  0.8298238353729248,\n",
       "  0.807292649269104,\n",
       "  0.8321868683497111,\n",
       "  0.7977085065841675,\n",
       "  0.8046700657208761,\n",
       "  0.8130270309448242,\n",
       "  0.785841152826945,\n",
       "  0.8002807728449504,\n",
       "  0.7893256537119547,\n",
       "  0.7834972955385844,\n",
       "  0.8380566665331523]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
