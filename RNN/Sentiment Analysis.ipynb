{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Follow https://nthu-datalab.github.io/ml/labs/13_Sentiment_Analysis_and_Neural_Machine_Translation/13_Sentiment_Analysis_and_Neural_Machine_Translation.html\n",
    "# It contains two topic about RNN (two examples)\n",
    "# 1. Sentiment Analysis\n",
    "# 2. Neural Machine Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(directory):\n",
    "    data = []\n",
    "    for f in os.listdir(directory)[:1000]:\n",
    "        content = open(directory + f, 'r', encoding='utf8').read()\n",
    "        data.append((content, int(f[-5]) > 5))\n",
    "    return data\n",
    "\n",
    "train_data = read_file('../../dataset/aclImdb/train/neg/') + read_file('../../dataset/aclImdb/train/pos/')\n",
    "test_data = read_file('../../dataset/aclImdb/test/neg/') + read_file('../../dataset/aclImdb/test/pos/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple vs banana: 0.583184\n",
      "apple vs mac: 0.574916\n",
      "banana vs mac: 0.243292\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# nlp = spacy.load('en')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "w_apple = nlp('apple')\n",
    "w_banana = nlp('banana')\n",
    "w_mac = nlp('mac')\n",
    "\n",
    "print(\"%s vs %s: %.6f\" % (w_apple, w_banana, w_apple.similarity(w_banana)))\n",
    "print(\"%s vs %s: %.6f\" % (w_apple, w_mac, w_apple.similarity(w_mac)))\n",
    "print(\"%s vs %s: %.6f\" % (w_banana, w_mac, w_banana.similarity(w_mac)))\n",
    "# Do not know why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unknown_words(data):\n",
    "    new_data = []\n",
    "    for content, label in data:\n",
    "        s = ' '.join([w for w in content.split(' ') if w in nlp.vocab])\n",
    "        new_data.append((s, label))\n",
    "    return new_data\n",
    "\n",
    "train_dat = remove_unknown_words(train_data)\n",
    "test_dat = remove_unknown_words(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 避免 padding 太多導致學不到東西，先將 data 分類\n",
    "class BatchGenerator:\n",
    "    def __init__(self, dat, batch_size):\n",
    "        n = len(dat)\n",
    "        n_batch = n // batch_size + 1\n",
    "        self.batch_xs, self.batch_ys, self.reviews = [], [], []\n",
    "        padding_vec = nlp(' ').vector\n",
    "\n",
    "        dat = sorted(map(lambda pair: (nlp(pair[0]), pair[1]), dat), key=lambda x: len(x[0]))\n",
    "        for i in range(n_batch):\n",
    "            print(\"第 {}/{} 個 batch\".format(i+1, n_batch))\n",
    "            \n",
    "            batch_dat = dat[i*batch_size : (i+1)*batch_size]\n",
    "            if not batch_dat: continue\n",
    "            \n",
    "            longest = len(batch_dat[-1][0])            \n",
    "            batch_x = np.zeros((batch_size, longest, 300))\n",
    "            batch_y = np.zeros((batch_size, 2))    # label for 0,1 # 0 - 9\n",
    "            review  = []\n",
    "            \n",
    "            for j, each in enumerate(batch_dat):\n",
    "                for k, w in enumerate(each[0]):\n",
    "                    batch_x[j][k] = w.vector        # use existing Word2vec model\n",
    "                for k in range(k, longest):\n",
    "                    batch_x[j][k] = padding_vec     # padding with ' '\n",
    "\n",
    "                batch_y[j][each[1]] = 1             # represent class as one-hot encoding\n",
    "                review.append(each[0])\n",
    "            \n",
    "            self.batch_xs.append(batch_x)\n",
    "            self.batch_ys.append(batch_y)\n",
    "            self.reviews.append(review)\n",
    "        \n",
    "    def get(self, batch_id):\n",
    "        # print(len(self.batch_xs))\n",
    "        return self.batch_xs[batch_id], self.batch_ys[batch_id], self.reviews[batch_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-3713c00d58c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3b1aaecd10a4>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dat, batch_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpadding_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第 {}/{} 個 batch\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-3b1aaecd10a4>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(pair)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mpadding_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mdat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"第 {}/{} 個 batch\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.__call__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.parse_batch\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.get_batch_model\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(seqs_in, drop)\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mseq\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseqs_in\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         X, bp_layer = layer.begin_update(layer.ops.flatten(seqs_in, pad=pad),\n\u001b[0;32m--> 280\u001b[0;31m                                          drop=drop)\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbp_layer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36muniqued_fwd\u001b[0;34m(X, drop)\u001b[0m\n\u001b[1;32m    372\u001b[0m                                                     return_counts=True)\n\u001b[1;32m    373\u001b[0m         \u001b[0mX_uniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 374\u001b[0;31m         \u001b[0mY_uniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_Y_uniq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_uniq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    375\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_uniq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mY_uniq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0muniqued_bwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/api.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_layer_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minc_layer_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcontinue_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36mbegin_update\u001b[0;34m(self, X, drop)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackprop_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchild\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_moments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mXhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/thinc/neural/_classes/layernorm.py\u001b[0m in \u001b[0;36m_get_moments\u001b[0;34m(ops, X)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_get_moments_reproduce_bug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-08\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch = BatchGenerator(train_dat, 128)\n",
    "\n",
    "xs, ys, rv = batch.get(0)\n",
    "print(xs[0])\n",
    "print(ys[0])\n",
    "print(rv[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "class SentimentReviewRNN:\n",
    "\n",
    "    def __init__(self):\n",
    "        with tf.variable_scope('rnn_i/o'):\n",
    "            # use None for batch size and dynamic sequence length\n",
    "            self.inputs = tf.placeholder(tf.float32, shape=[None, None, 300])\n",
    "            self.groundtruths = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "\n",
    "        with tf.variable_scope('rnn_cell'):\n",
    "            self.cell = tf.contrib.rnn.LSTMCell(128)\n",
    "            # project RNN output into target class dimension\n",
    "            self.out_cell = tf.contrib.rnn.OutputProjectionWrapper(self.cell, 2)\n",
    "\n",
    "        with tf.variable_scope('rnn_forward'):\n",
    "            # use dynamic_rnn for different length\n",
    "            self.outputs, _ = tf.nn.dynamic_rnn(self.out_cell, self.inputs, dtype=tf.float32)\n",
    "            self.outputs = self.outputs[:, -1, :]  # only use the last output of sequence\n",
    "\n",
    "        with tf.variable_scope('rnn_loss'):\n",
    "            # use cross_entropy as class loss\n",
    "            self.loss = tf.losses.softmax_cross_entropy(onehot_labels=self.groundtruths, logits=self.outputs)\n",
    "            self.optimizer = tf.train.AdamOptimizer(0.1).minimize(self.loss)\n",
    "\n",
    "        with tf.variable_scope('rnn_accuracy'):\n",
    "            self.accuracy = tf.contrib.metrics.accuracy(labels=tf.argmax(self.groundtruths, axis=1), \n",
    "                                                        predictions=tf.argmax(self.outputs, axis=1))\n",
    "\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(tf.global_variables_initializer())  # don't forget to initial all variables\n",
    "        self.saver = tf.train.Saver()  # a saver is for saving or restoring your trained weight\n",
    "\n",
    "    def train(self, batch_x, batch_y):\n",
    "        fd = {}\n",
    "        fd[self.inputs] = batch_x\n",
    "        fd[self.groundtruths] = batch_y\n",
    "        # feed in input and groundtruth to get loss and update the weight via Adam optimizer\n",
    "        loss, accuracy, _ = self.sess.run([self.loss, self.accuracy, self.optimizer], fd)\n",
    "\n",
    "        return loss, accuracy\n",
    "\n",
    "    def test(self, batch_x, batch_y):\n",
    "        fd = {}\n",
    "        fd[self.inputs] = batch_x\n",
    "        fd[self.groundtruths] = batch_y\n",
    "        prediction, accuracy = self.sess.run([self.outputs, self.accuracy], fd)\n",
    "\n",
    "        return prediction, accuracy\n",
    "\n",
    "    def save(self, e):\n",
    "        self.saver.save(self.sess, 'model/rnn/rnn_%d.ckpt' % (e + 1))\n",
    "\n",
    "    def restore(self, e):\n",
    "        self.saver.restore(self.sess, 'model/rnn/rnn_%d.ckpt' % (e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第 1/8 個 batch\n",
      "第 2/8 個 batch\n",
      "第 3/8 個 batch\n",
      "第 4/8 個 batch\n",
      "第 5/8 個 batch\n",
      "第 6/8 個 batch\n",
      "第 7/8 個 batch\n",
      "第 8/8 個 batch\n",
      "第 1/8 個 batch\n",
      "第 2/8 個 batch\n",
      "第 3/8 個 batch\n",
      "第 4/8 個 batch\n",
      "第 5/8 個 batch\n",
      "第 6/8 個 batch\n",
      "第 7/8 個 batch\n",
      "第 8/8 個 batch\n"
     ]
    }
   ],
   "source": [
    "# hyperparameter of our network\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 256\n",
    "train_batch = BatchGenerator(train_dat, BATCH_SIZE)\n",
    "test_batch = BatchGenerator(test_dat, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(train_dat) // BATCH_SIZE\n",
    "n_test = len(test_dat) // BATCH_SIZE\n",
    "tf.reset_default_graph()\n",
    "model = SentimentReviewRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_loss = []\n",
    "\n",
    "for e in range(EPOCHS):  # train for several epochs\n",
    "    loss_train = 0\n",
    "    accuracy_train = 0\n",
    "\n",
    "    for b in range(n_train):  # feed batches one by one\n",
    "        batch_x, batch_y, _ = train_batch.get(b)\n",
    "        loss_batch, accuracy_batch = model.train(batch_x, batch_y)\n",
    "\n",
    "        loss_train += loss_batch\n",
    "        accuracy_train += accuracy_batch\n",
    "\n",
    "    loss_train /= n_train\n",
    "    accuracy_train /= n_train\n",
    "\n",
    "#     model.save(e)  # save your model after each epoch\n",
    "    rec_loss.append([loss_train, accuracy_train])\n",
    "\n",
    "# np.save('./model/rnn/rec_loss.npy', rec_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1902387355055128\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl4XPV97/H3V6PNErI2C9sgG9nYYglgMAIaNkMgYHhSKKElkDQXyELztCy5uTcNWS5N6NPecpsuaUJDoQEXHmpKCLUJIQgaIJRACDa7bZBlY2MZr5LlXdYy3/vHGcmyrGWkOaPxOf68nkfPzJxz9Dvf47G/8/N3fuf3M3dHRETiJS/XAYiISPiU3EVEYkjJXUQkhpTcRURiSMldRCSGlNxFRGJIyV1EJIaU3EVEYkjJXUQkhvJzdeJJkyZ5XV1drk4vIhJJS5cu3eruNSMdl7PkXldXx5IlS3J1ehGRSDKztekcp7KMiEgMKbmLiMTQiMndzO43s81m9u4Q+z9nZm+b2Ttm9rKZzQk/TBERGY10au4LgB8BDw6x/wNgnrtvM7PLgHuBs8IJT0SiqKuri5aWFjo6OnIdSmQVFxdTW1tLQUHBmH5/xOTu7i+aWd0w+1/u9/K3QO2YIhGR2GhpaaGsrIy6ujrMLNfhRI6709raSktLCzNmzBhTG2HX3L8I/DLkNkUkYjo6OqiurlZiHyMzo7q6OqP/+YQ2FNLMLiRI7ucOc8xNwE0A06dPD+vUInIIUmLPTKZ/fqH03M3sFOBfgSvdvXWo49z9XndvcPeGmpoRx+AP6r2NO/jbxvfYtrtzjNGKiMRfxsndzKYDjwOfd/emzEMa3pqtu7n7+VV8tH1vtk8lIhF2xBFH5DqEnBqxLGNmC4ELgElm1gL8BVAA4O73AHcA1cA/p/4b0e3uDdkKuLKkEIBtu7uydQoRkchLZ7TMdSPs/xLwpdAiGkFlaSq571FZRkRGZ82aNXzhC19g69at1NTU8MADDzB9+nR++tOf8r3vfY9EIkF5eTkvvvgiy5Yt48Ybb6Szs5NkMsnPfvYzZs+enetLSFvO5pYZq4qSYMxnu5K7SCR87+fLWP7RjlDbPPGoifzF739s1L93yy23cP3113P99ddz//33c+utt7Jo0SLuvPNOGhsbOfroo2lvbwfgnnvu4bbbbuNzn/scnZ2d9PT0hHoN2Ra56Qd6yzJtKsuIyCi98sorfPaznwXg85//PC+99BIA55xzDjfccAP33XdfXxL/+Mc/zl//9V9z1113sXbtWiZMmJCzuMcicj33gkQeZUX5KsuIRMRYetjj7Z577uHVV1/lF7/4BaeffjpLly7ls5/9LGeddRa/+MUvuPzyy/mXf/kXPvGJT+Q61LRFrucOUFFaoLKMiIza2WefzSOPPALAww8/zHnnnQfAqlWrOOuss7jzzjupqalh3bp1rF69mpkzZ3Lrrbdy5ZVX8vbbb+cy9FGLXM8doKqkkG17VJYRkaHt2bOH2tr9s6F87Wtf44c//CE33ngjf/u3f9v3hSrA17/+dVauXIm7c9FFFzFnzhzuuusuHnroIQoKCpgyZQrf+ta3cnUpYxLJ5F5RUqiyjIgMK5lMDrr9ueeeO2jb448/ftC222+/ndtvvz30uMZLJMsylSUFSu4iIsOIZHKvKCmkXaNlRESGFMnkXlVayM593XR2D/7fLhGRw10kk3tl741Me1WaEREZTCSTe0XqRqZ2jZgRERlUJJN7VWnvXarquYuIDCaSyV3zy4hIOhYtWoSZ8d577+U6lHEXyeTeN+2vyjIiMoyFCxdy7rnnsnDhwqyd41CdUCziyV09dxEZ3K5du3jppZf4yU9+0jflAMBdd93FySefzJw5c/puUmpububiiy9mzpw5zJ07l1WrVvHCCy/wqU99qu/3br75ZhYsWABAXV0d3/jGN5g7dy4//elPue+++zjjjDOYM2cOV199NXv27AFg06ZNXHXVVcyZM4c5c+bw8ssvc8cdd/CP//iPfe1++9vf5gc/+EHo1x/JO1QnFCYoLsjTUnsiUfDL22HjO+G2OeVkuOxvhj1k8eLFzJ8/n/r6eqqrq1m6dCmbN29m8eLFvPrqq5SUlNDW1gbA5z73OW6//XauuuoqOjo6SCaTrFu3btj2q6uref311wFobW3ly1/+MgDf+c53+MlPfsItt9zCrbfeyrx58/jP//xPenp62LVrF0cddRSf/vSn+epXv0oymeSRRx7hd7/7XQh/KAdKZyWm+4FPAZvd/aRB9h8PPADMBb7t7t8PPcpBVGp+GREZxsKFC7ntttsAuPbaa1m4cCHuzo033khJSQkAVVVV7Ny5k/Xr13PVVVcBUFxcnFb7n/nMZ/qev/vuu3znO9+hvb2dXbt2cemllwLBVAcPPvggQN9CIOXl5VRXV/PGG2+wadMmTjvtNKqrq0O77l7p9NwXAD8CHhxifxtwK/AHIcWUloqSQn2hKhIFI/Sws6GtrY3nnnuOd955BzOjp6cHM+OP/uiP0m4jPz//gPlpOjo6DthfWlra9/yGG25g0aJFzJkzhwULFvDCCy8M2/aXvvQlFixYwMaNG/nCF76QdkyjMWLN3d1fJEjgQ+3f7O6vAePaja4qLdBQSBEZ1GOPPcbnP/951q5dy5o1a1i3bh0zZsygvLycBx54oK8m3tbWRllZGbW1tSxatAiAffv2sWfPHo455hiWL1/Ovn37aG9v51e/+tWQ59u5cydTp06lq6uLhx9+uG/7RRddxI9//GMg+OJ1+/btAFx11VU8/fTTvPbaa329/LBF8gtV6O25qywjIgdbuHBhX5ml19VXX82GDRu44ooraGho4NRTT+X73w+qyA899BD/9E//xCmnnMLZZ5/Nxo0bmTZtGtdccw0nnXQS11xzDaeddtqQ5/vLv/xLzjrrLM455xyOP/74vu0/+MEPeP755zn55JM5/fTTWb58OQCFhYVceOGFXHPNNSQSiSz8CYC5+8gHmdUBTw5Wc+93zHeBXcPV3M3sJuAmgOnTp5++du3aUYa733cWvcMv3t7AG3dcMuY2RCQ7VqxYwQknnJDrMA5ZyWSyb6TNcItuD/bnaGZL3b1hpHOMa8/d3e919wZ3b6ipqcmoraqSQtr3dtGTHPnDSUTkULF8+XJmzZrFRRddNGxiz1Qkh0JCUJZxhx17u6hMTUcgInKoO/HEE1m9enXWz5POUMiFwAXAJDNrAf4CKABw93vMbAqwBJgIJM3sq8CJ7r4ja1EDlaXBFATb9nQquYscgtwdM8t1GJGVTsl8OCMmd3e/boT9G4Ha4Y7JhgpNQSByyCouLqa1tZXq6mol+DFwd1pbW9Mecz+YyJZlqnqTu4ZDihxyamtraWlpYcuWLbkOJbKKi4sPWOB7tCKb3DW/jMihq6CggBkzZuQ6jMNadMe5l/ZO+6uyjIjIQJFN7mVF+eTnGW3quYuIHCSyyd3MNL+MiMgQIpvcIVgoe9tulWVERAaKdnIvLVRZRkRkENFO7iUFKsuIiAwi4sldC3aIiAwm0sm99wvVTG/TFRGJm0gn96rSArp6nF37unMdiojIISXSyb13fhndyCQicqBIJ3dNQSAiMrhIJ/eq1BQEWktVRORAkU7uKsuIiAwu0sldZRkRkcGNmNzN7H4z22xm7w6x38zsn8ys2czeNrO54Yc5uPIJBZhpTncRkYHS6bkvAOYPs/8yYHbq5ybgx5mHlZ5EnlE+oUA3MomIDJDOMnsvmlndMIdcCTzowZ1EvzWzCjOb6u4bQopxWMFdquq5H3J6uiBREG6be9qCdkWirrAEisqyeoowVmI6GljX73VLatu4JPeKkgJ9oXqoWfEkPH4T3LIUJk4Np813H4fHbgynLZFcO+er8MnvZfUU47rMnpndRFC6Yfr06aG0WVVSyIbtHaG0JSF556fQtRuafgkNXwinzWWPwxGTYd43wmlPJJemnJL1U4SR3NcD0/q9rk1tO4i73wvcC9DQ0BDKhDAVJYWs2LAjjKYkDD1dsOq54HnTM+Ek9+5OWPU8nPyHcMYXM29P5DAQxlDIJ4D/kRo183vA9vGqt0NqwQ6VZQ4dH74C+3ZA5QxY/QJ07c28zbW/gc5dMPvSzNsSOUykMxRyIfAKcJyZtZjZF83sK2b2ldQhTwGrgWbgPuBPsxbtICpLC9nb1UNHV894nlaG0tQIiUK4+LvQvRfWvJR5myufgUQRzJyXeVsih4l0RstcN8J+B/4stIhGqf+NTFPLJ+QqDOnV1Ah150L9fCgogaanYfYnM29zxnlQWBpOjCKHgUjfoQpBWQbQWqqHgrbV0LoyKJ8UFMPMC4K6eybz7W9thrZVwYeFiKQt+sm9VFMQHDKangke6y9JPV4K2z+ELe+Nvc2VjcHj7Esyi03kMBP95K75ZQ4dTU/DpHqomhm87k3ITU9n1mbNCVB5TObxiRxGYpDcU2UZjZjJrX07g1Et9f1GtEw8KhjP29ujH62OHbD25f3/ExCRtEU+ufdN+6vJw3Jr9QvQ03nwcMX6S2Hdb4OpA0Zr1XOQ7NYQSJExiHxyL8zP44iifNpUlsmtpkYoKofpv3fg9vr54Mn9NzaNxspnoLgcpp0VTowih5HIJ3fQ/DI5l0wGiXjWJw6eLOyouVAyafR19742L4bEuM6SIRILsUjumhkyxza+Bbs2DV4+ycsLvlht/i/o6U6/zY/egN1bNARSZIzikdxLC7VgRy41NQI29M1K9ZfA3m3Q8lr6ba5sBMsLeu4iMmrxSO6aXya3mhqhtgFKJw2+/9hPQF7+/jHrabX5NNSeCSVV4cQocpiJSXJXWSZndm6Cj14/cAjkQMXlMP3jqR5+GnZsgA1vaQikSAZikdwrSgrY2dFNV08y16EcfpqfDR5HGq5YfylsXg7tH47c5sreO11VbxcZq1gk96rUFAQaMZMDTU9D2VEw5eThj+tN1On03lc+AxNr4cgTM49P5DAVi+TedyOTSjPjq3cRjfpLwGz4Y6tnBXO8rxzhbtXufak2Lx25TREZUiySu6YgyJHeRTTSKZ+YBcd98CJ07hn6uDUvBUv0DVfDF5ERxSS5Bz33Ng2HHF+9i2jMOD+94+svge6OIMEPpakR8iek36aIDCqt5G5m883sfTNrNrPbB9l/jJn9yszeNrMXzKw2/FCHVlmqskxONDUGSTjdRTSOOQcKjxj6blX3YLjkjPOhQAuviGQinWX2EsDdwGXAicB1Zjbwm67vAw+6+ynAncD/DTvQ4agskwN9i2iMonySXxQs4LFyiAU8tq6EbWtUkhEJQTo99zOBZndf7e6dwCPAlQOOORHonRnq+UH2Z9WEggRF+Xka6z6exrqIRv182LEeNr178L7eHr0W5hDJWDrJ/WhgXb/XLalt/b0FfDr1/CqgzMyqMw8vPWYW3Mikmvv4GesiGn0LeAwyJHLlM3Dkx6BiWubxiRzmwvpC9X8D88zsDWAesB7oGXiQmd1kZkvMbMmWLVtCOnWgQlMQjJ++RTTGUD4pmwxHnXbwkMi97WNvU0QOkk5yXw/070rVprb1cfeP3P3T7n4a8O3UtvaBDbn7ve7e4O4NNTU1GYR9ME1BMI56F9EYayKefSms+x3sbj2wTe9RchcJSTrJ/TVgtpnNMLNC4Frgif4HmNkkM+tt65vA/eGGObKqUiX3cbPyGSiuCCb2Gov6SwEPpgHu1dQIEyqh9oxQQhQ53I2Y3N29G7gZaARWAI+6+zIzu9PMrkgddgHwvpk1AZOBv8pSvEPSgh3jJIxFNKaeCqVH7v8CNdkTzFEz65OQlwgvVpHDWFr/Ot39KeCpAdvu6Pf8MeCxcEMbncqSQtr3dJJMOnl5um09a8JYRCMvL7ihacXPoacLPnoT9rSqJCMSoljcoQrBjUxJhx0d6r1nVdPTqUU0LsqsndmXQsd2WPdqqs1E5m2KSJ/4JHfdyDQ+VjYGC1ZnuojGsRdCXkFQa1/ZGCysPaEynBhFJE7JPZiCQF+qZlHvIhph3GRUVAZ158Dbj8LGd3TjkkjI4pPcU/PL6EamLOpbRCOk2nj9fNi1cf9zEQlNfJK7yjLZt/IZKJ8W3iIavb31iulQc1w4bYoIkOZomSjQgh3jYO3LcPzl4S2iUX0s1J0XzAKphTlEQhWb5D6xOJ9EnmlO92zZ0wZ726Dm+HDbveHJcNsTESBGZZlg8jDNL5M1bauDx+pZuY1DRNISm+QOQWlGZZksaW0OHpXcRSIhVsk96LkruWdFa3Nw81LFKKf4FZGciFlyL2TbbpVlsqK1OUjs+YW5jkRE0hC/5K6ee3a0rlJJRiRCYpXcK0qDmSF9sPU5ZezcldxFIiZWyb2qpJDOniS7Ow9aBEoysXMjdO0OxqWLSCTEKrn3zS+jse7halsVPCq5i0RGrJJ7RWoKAi3aETINgxSJnLSSu5nNN7P3zazZzG4fZP90M3vezN4ws7fN7PLwQx1Z7+RhbfpSNVytzZAogom1uY5ERNI0YnI3swRwN3AZcCJwnZkNnDnqOwTL751GsMbqP4cdaDoqNb9MdrSugqqZwQpKIhIJ6fxrPRNodvfV7t4JPAJcOeAYByamnpcDH4UXYvr6ZoZUzT1cratUbxeJmHSS+9HAun6vW1Lb+vsu8Mdm1kKw1uotgzVkZjeZ2RIzW7Jly5YxhDu88gma9jd0yZ5gXhnV20UiJaz/Z18HLHD3WuBy4CEzO6htd7/X3RvcvaGmpiakU++Xn8ijfIKmIAhV+4eQ7FLPXSRi0knu64Fp/V7Xprb190XgUQB3fwUoBiaFEeBoaWbIkPUNg1TPXSRK0knurwGzzWyGmRUSfGH6xIBjPgQuAjCzEwiSe/h1lzRoZsiQtSq5i0TRiMnd3buBm4FGYAXBqJhlZnanmV2ROux/AV82s7eAhcANnqM5ACpLCrRgR5ham6FoIpSGX0YTkexJayUmd3+K4IvS/tvu6Pd8OXBOuKGNTWVpIU2bduU6jPhobQ6GQWoZPJFIid3AZc0MGTJNGCYSSTFM7gXs6eyho0uTh2Wse18wWkbJXSRy4pfcS3vvUtWImYy1fQC4krtIBMUvuffODKnSTOb6Jgybmds4RGTUYpfce2eGVHIPQe8Y9yrdwCQSNbFL7lWlvXO6qyyTsdbmYAjkhIpcRyIioxS75K6yTIg0UkYksmKX3Pcv2KHknrHWVSrJiERU7JJ7UX6CksIEbSrLZGbfTti1UROGiURU7JI7BKUZ9dwzpDllRCItnsm9VNP+ZqxvGKR67iJRFM/kXlJIm25iykzb6uCxSmPcRaIotsldZZkMtTZD+TQomJDrSERkDGKa3Au0jmqmWptVkhGJsFgm94qSQnZ0dNPdk8x1KNHknprqV8ldJKpimdx771Jt36u6+5jsaYOO7RopIxJhaSV3M5tvZu+bWbOZ3T7I/n8wszdTP01m1h5+qOnTjUwZ6hspo+QuElUjrsRkZgngbuCTQAvwmpk9kVp9CQB3/5/9jr8FOC0LsaZt/xQE6rmPiYZBikReOj33M4Fmd1/t7p3AI8CVwxx/HcE6qjnTm9y1luoYta2CvHyoOCbXkYjIGKWT3I8G1vV73ZLadhAzOwaYATw3xP6bzGyJmS3ZsmXLaGNNW2WpyjIZaW2GyjpIpLXErogcgsL+QvVa4DF3H3SNO3e/190b3L2hpqYm5FPvp7JMhjQbpEjkpZPc1wPT+r2uTW0bzLXkuCQDUFKYoDCRp7HuY5FMKrmLxEA6yf01YLaZzTCzQoIE/sTAg8zseKASeCXcEEfPzDS/zFjt3ADdezXtgEjEjZjc3b0buBloBFYAj7r7MjO708yu6HfotcAj7u7ZCXV0KksKVZYZCw2DFImFtL4xc/engKcGbLtjwOvvhhdW5ipKCvSF6lgouYvEQizvUIXgLlUNhRyDttWQPwHKpuY6EhHJQGyTe0VJIe0qy4xe74RhebH9qyFyWIjtv+DKkgLa93aRTB4SXwFEh2aDFImFGCf3QnqSzs6O7lyHEh093bBtjertIjEQ6+QOaDjkaLSvhWS3pvoViYH4JvfUFARK7qOgRbFFYiO2yb1CPffR0zBIkdiIbXKv6k3uuzViJm2tzVBcASVVuY5ERDIU2+SumvsYtK0KRsqY5ToSEclQbJN7WXE+eYbGuo+GJgwTiY3YJve8PKOipJA29dzT07UXtq9TcheJidgmd4Ajy4pYv21vrsOIhrYPgkfdwCQSC7FO7mfOqOJ3H7Sxr3vQtUOkv96RMhrjLhILsU7u8+pr2NvVw5I123IdyqFPi2KLxEqsk/vvzaymMJHHr5uyt15rbLSugiOmQFFZriMRkRDEOrmXFuXTUFfJi0ruI+sdBikisZBWcjez+Wb2vpk1m9ntQxxzjZktN7NlZvbv4YY5dvPqa3hv4042bu/IdSiHNs0GKRIrIyZ3M0sAdwOXAScC15nZiQOOmQ18EzjH3T8GfDULsY7JvONqANR7H07Hdti9RcMgRWIknZ77mUCzu692907gEeDKAcd8Gbjb3bcBuPvmcMMcu+MmlzF5YhG/XqnkPiRNGCYSO+kk96OBdf1et6S29VcP1JvZb8zst2Y2f7CGzOwmM1tiZku2bBmfZGtmnD+7hpdWbqW7Jzku54yc3uSuYZAisRHWF6r5wGzgAuA64D4zqxh4kLvf6+4N7t5QU1MT0qlHNu+4Grbv7eKtlu3jds5IaW0GDKpm5DoSEQlJOsl9PTCt3+va1Lb+WoAn3L3L3T8AmgiS/SHh3FmTyDPV3YfU2gwV0yG/KNeRiEhI0knurwGzzWyGmRUC1wJPDDhmEUGvHTObRFCmWR1inBmpKClkzrQKjXcfSpsmDBOJmxGTu7t3AzcDjcAK4FF3X2Zmd5rZFanDGoFWM1sOPA983d1bsxX0WMyrr+Gtlna27dZEYgdwT80GqXq7SJykVXN396fcvd7dj3X3v0ptu8Pdn0g9d3f/mruf6O4nu/sj2Qx6LM6vr8EdXmremutQDi27t8C+Heq5i8RMfq4DyKpta2DrSgDmJJ3Li99l09IWKJl58LHFFTDtjPGNr1fbB0HvOS8P8vLBEsFjXgIsr9/z1GvvgWRP6rEbksl+z3v270/H1qbgUT13kViJb3JPJmHB78P2DwFIAP8M8CHw8BC/8ycvwtQ54xNfL3dY8CnY0TK+5+3P8qDmhNydX0RCF9/kvn5pkNgvugNmzAPgv1Zs4kfPNfMPnzmVGZNK9x/buRsevBLe/+X4J/cNbwWJ/cJvQ915Qe+7t+fdvxfeu9091ZtP9OvlJ/b37PtvT3e5vAmVUD7w1gURibL4JvfliyCvABq+CBOCIfcnT+zgzV9B4/ZavnLqgDJEbQM0PQ0XDDp1TvY0NQIGp98IR4zf2H8Ribd4zgrpDsufgGMv7EvsAJMnFnP8lDJ+/f4gQyLrL4WP3oCdm8YxUGBlIxx9uhK7iIQqnsn9ozeCksyJA6fACYZELlnbxu593QfumH1p8Nj87DgEmLJrM6x/HeoHna1BRGTM4pncly8O6s7HXX7Qrnn1NXT1OK+sGjAMf8rJUHZUUJoZLyufBRzqLxm/c4rIYSF+yd09SO4zzoeSqoN2n15XSUlh4uC7Vc2CJLvqeegepxudVjZC2VSYcsr4nE9EDhvxS+4b34FtHwxakgEoyk/w8ZnVvDjYFMD186FzF6z9TZaDJPgAaX4OZl+S/qgWEZE0xS+5L18cDBU8/lNDHjLvuBrWtu5hzdbdB+6YcT4kimDlM1kOEvjwFejcqXq7iGRFvJK7ezAEsu5cKJ005GHz6oORKQeVZgpLYcZ541N3b2oMPkhmzsv+uUTksBOv5L55RTB97RAlmV7HVJdyTHXJ4FMA18+HttWwtTlLQaasbAw+SApLRz5WRGSU4pXcly8GDI7//REPnVdfw8urWtnXPWAOltmpkSvZ7L23rgo+hHqHX4qIhCx+yf2Ys6Fs8oiHzquvYW9XD0vWbDtwR+UxwTwrKxuzFCSpu1LREEgRyZr4JPct78OWFSOWZHr93sxqChI2RGnmElj7MnRkaVm+pqeh5niorMtO+yJy2ItPcl+eWhzqhJFLMgClRfmcUVc1+OpM9fODibpWPR9igCn7dgYfHLPVaxeR7EkruZvZfDN738yazeygmbXM7AYz22Jmb6Z+vhR+qCNYvhimnQUTj0r7V+bV1/Dexp1s3N5x4I7aM4P53bMxJHLV85Ds0hBIEcmqEZO7mSWAu4HLgBOB68zsxEEO/Q93PzX1868hxzm81lWw6Z20SzK95h0XDIk86IamRD7MujhI7slkWFEGmhqhuDz4IBIRyZJ0eu5nAs3uvtrdO4FHgNFl0Wxbvjh4POGK4Y8b4LjJZUyeWDREaebSYAm6j94IIcCUZDL4wJh1cfABIiKSJekk96OBdf1et6S2DXS1mb1tZo+Z2bTBGjKzm8xsiZkt2bJlkIQ6VssXB9PmVgx62iGZGefPruGllVvpSfqBO2ddHNzpGuaQyA1vwO7NGgIpIlkX1heqPwfq3P0U4Fng3wY7yN3vdfcGd2+oqQlp/vJta2DDm6MuyfSad1wN2/d28VZL+4E7SqqC2nuYQyKbngk+MGZdHF6bIiKDSCe5rwf6d4lrU9v6uHuru+9LvfxX4PRwwktD3yiZ0ZVkep07axJ5xtALeGx4C3ZsyCDAfpqehtozoLQ6nPZERIaQTnJ/DZhtZjPMrBC4Fnii/wFmNrXfyyuAFeGFOILli4N1T6tmjOnXK0oKmTOtYui6O4QzambnxuB/GPUqyYhI9o2Y3N29G7gZaCRI2o+6+zIzu9PMervLt5rZMjN7C7gVuCFbAR+gfR2sXzLmkkyvefU1vNXSzoetew7cceSJUD5t/x2lmej9gFC9XUTGQVo1d3d/yt3r3f1Yd/+r1LY73P2J1PNvuvvH3H2Ou1/o7u9lM+g+K34ePJ6QWXL/9Gm1lBXlc8MDv6N11779O8yCm41WvwBdHUP+flqaGmFiLUz+WGbtiIikIdp3qC5fDJNPgkmzMmpmenUJ999wBuvb93LjgtfY1X991fpLoWs3rH1p7Cfo3hfcvFSvhTlEZHzjQ/CaAAAJlUlEQVREN7nv+AjW/Tbjkkyvhroq/vlzc1n20Q6+8tBSOrtTNy/NOB/yJwQjXcZq7W+CDwjdlSoi4yS6yX3Fk8FjSMkd4KITJnPX1afwUvNWvvbomySTDgUTggTf9HSwGMhYNDVCfjHUnRdarCIiw4lucl++OJhZsea4UJv9w9Nr+eZlx/Pk2xv43s+X4e5BaaZ9LWxtGn2D7kFynzEPCktCjVVEZCjRvAd+1+ag1DHvz7PS/J/MO5bW3Z3c++JqJh1RxC2n9y7g0Tj6D5PW5mDB7rNvDj9QEZEhRLPn/t6TgIdakhno9vnH8+m5R/N3zzbx8PvJ4IvbsQyJ7J2+QEMgRWQcRTO5L18M1bOCcehZkpdn3HX1KXzi+CP5P4veZVXF2fDhK7C3feRf7q+pEY782KjnvRERyUT0kvvuVvjgv4Nee5aHFRYk8rj7s3M5bXol31p2NHgPrPpV+g10bA8+EHRXqoiMs+gl96ZfBkk2iyWZ/iYUJvjJ9Q1srzqFbV7GtjefTP+XVz0XrOik5C4i4yx6yf2Uz8D1T8KUU8btlBUlhSz44tm8mpiLNT9L88Y011ZtaoQJlcFkYSIi4yh6yT1RADPOG/c7PaeUF3PaxZ+hgp1880cP8OePvcUHW3cP/QvJHlj5LMz6JOQlxi9QERGiOhQyRyafdjn+bIIfHvEQ77z9JE1vOTvKi5k5qZSy4oIDD+7aA3u2qiQjIjmh5D4aEyqxs77ClA9+TXXZbtp2d9K+s5OWHXBEcT6TjihiQkG/XnrdecHEYyIi40zJfbTm/zUABcBkoGhPJwteXsMDv1nD9o+6OHfWJP70wmP5+MxqTJOEiUiOmI91vpQMNTQ0+JIlS3Jy7mzYta+bh3+7lvv++wO27trH3OkVfGXesZwzaxKlRfoMFZFwmNlSd28Y8Tgl93B1dPXw6JJ1/MuvV7O+fS+JPOP4KWWcfkwlpx9TydzpldRWTlCvXkTGJNTkbmbzgR8ACeBf3f1vhjjuauAx4Ax3HzZzxzW59+rqSfJS81ZeX7uNpWu38ea6dvZ09gBwZFkRc6enkv0xlZx09ESK8jWiRkRGlm5yH7FeYGYJ4G7gk0AL8JqZPeHuywccVwbcBrw6tpDjpSCRx4XHHcmFxx0JQHdPkvc37eT1tdt4/cN2lq7dxtPLNgJQmMijblIJkycWM7W8mCkTi5lSPoGp5cV92ypKCtTbF5G0pVMMPhNodvfVAGb2CHAlsHzAcX8J3AV8PdQIYyI/kcfHjirnY0eV8/mPB9s27+zg9bXtvPHhNta07mbjjn00bdrC5p37Dpo6vig/jynlxRxZVsQRRfmUFuVTWph6LEpQUpjPEanH3m1F+QkKEkZBIo/81GNBXr/nCSM/kUd+npGfZyTyTB8gIjGRTnI/GljX73ULcFb/A8xsLjDN3X9hZkMmdzO7CbgJYPr06aOPNmaOLCtm/klTmH/SlAO2d/ck2bJrHxu2d7Cx92dHBxu2d7B5Rwdbd3WytnUPuzu72b2vh92d3WNeR2QgM0iYkZdnJCxI+L0/eWbkGeSZYQYGWOp5Xv9HCHamY7y/8hkkrsFC1YecZNO1Z0zjS+fNzOo5Mh7GYWZ5wN8DN4x0rLvfC9wLQc0903PHVX4ij6nlE5haPiGt492dvV097N7Xw57ObnbtC5J+Z3eSrp7gpzvpqedOd09y//Nk8JhMOt1JJ+lOT9Lp8WBbTxKSHhzXkwzO5R5sc4K1SDz1PDlgX7rpcbwS6WDfLw36l3CQjY5jaV+RyPAmHVGU9XOkk9zXA/3nq61NbetVBpwEvJD6RzoFeMLMrhjpS1UJh5lRUphPSWE+kP2/NCJy6EtnbpnXgNlmNsPMCoFrgSd6d7r7dnef5O517l4H/BZQYhcRyaERk7u7dwM3A43ACuBRd19mZnea2RXZDlBEREYvrZq7uz8FPDVg2x1DHHtB5mGJiEgmojflr4iIjEjJXUQkhpTcRURiSMldRCSGlNxFRGIoZ1P+mtkWYO0Yf30SsDXEcA4FcbumuF0PxO+a4nY9EL9rGux6jnH3mpF+MWfJPRNmtiSdKS+jJG7XFLfrgfhdU9yuB+J3TZlcj8oyIiIxpOQuIhJDUU3u9+Y6gCyI2zXF7XogftcUt+uB+F3TmK8nkjV3EREZXlR77iIiMozIJXczm29m75tZs5ndnut4wmBma8zsHTN708wiN1Wymd1vZpvN7N1+26rM7FkzW5l6rMxljKM1xDV918zWp96nN83s8lzGOBpmNs3Mnjez5Wa2zMxuS22P5Ps0zPVE+T0qNrPfmdlbqWv6Xmr7DDN7NZXz/iM19frI7UWpLJNarLuJfot1A9cNXKw7asxsDdDg7pEcn2tm5wO7gAfd/aTUtv8HtLn736Q+hCvd/Ru5jHM0hrim7wK73P37uYxtLMxsKjDV3V9PLWa/FPgDghXUIvc+DXM91xDd98iAUnffZWYFwEvAbcDXgMfd/REzuwd4y91/PFJ7Ueu59y3W7e6dQO9i3ZJD7v4i0DZg85XAv6We/xvBP7zIGOKaIsvdN7j766nnOwnWZjiaiL5Pw1xPZHlgV+plQerHgU8Aj6W2p/0eRS25D7ZYd6Tf0BQHnjGzpalFxONgsrtvSD3fCEzOZTAhutnM3k6VbSJRwhjIzOqA04BXicH7NOB6IMLvkZklzOxNYDPwLLAKaE8tmgSjyHlRS+5xda67zwUuA/4sVRKIDQ9qf9Gp/w3tx8CxwKnABuDvchvO6JnZEcDPgK+6+47++6L4Pg1yPZF+j9y9x91PJVir+kzg+LG2FbXkPtJi3ZHk7utTj5uB/yR4U6NuU6ou2lsf3ZzjeDLm7ptS//iSwH1E7H1K1XF/Bjzs7o+nNkf2fRrseqL+HvVy93bgeeDjQIWZ9a6al3bOi1pyH3ax7igys9LUF0KYWSlwCfDu8L8VCU8A16eeXw8szmEsoehNgilXEaH3KfVl3U+AFe7+9/12RfJ9Gup6Iv4e1ZhZRer5BIKBIysIkvwfpg5L+z2K1GgZgNTQpn8EEsD97v5XOQ4pI2Y2k6C3DsGatv8etWsys4XABQQz2G0C/gJYBDwKTCeY/fMad4/MF5RDXNMFBP/dd2AN8Cf96tWHNDM7F/hv4B0gmdr8LYI6deTep2Gu5zqi+x6dQvCFaYKg4/2ou9+ZyhGPAFXAG8Afu/u+EduLWnIXEZGRRa0sIyIiaVByFxGJISV3EZEYUnIXEYkhJXcRkRhSchcRiSEldxGRGFJyFxGJof8P+UtD3LM0VuEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rec_loss = np.load('./model/rnn/rec_loss.npy')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(rec_loss[0][0])\n",
    "plt_loss = plt.plot([rec_loss[i][0] for i in range(len(rec_loss))])\n",
    "plt_accuracy = plt.plot([rec_loss[i][1] for i in range(len(rec_loss))])\n",
    "plt.legend(['Loss', 'Accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: 1.0000\n"
     ]
    }
   ],
   "source": [
    "accuracy_test = 0\n",
    "\n",
    "for b in range(n_test):\n",
    "    batch_x, batch_y, _ = test_batch.get(b)\n",
    "    _, accuracy_batch = model.test(batch_x, batch_y)\n",
    "\n",
    "    accuracy_test += accuracy_batch\n",
    "\n",
    "accuracy_test /= n_test\n",
    "\n",
    "print('Test: %.4f' % (accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
