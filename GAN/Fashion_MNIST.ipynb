{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28) y_train shape: (60000,)\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape, \"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train set\n",
      "10000 test set\n",
      "y = 2 Pullover\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f22b7910c18>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFLJJREFUeJzt3WtwnOV1B/D/0e5Kq4stW74hbIO5GAghxIACbWFSEhIGKFOTmZYBmoyb0DgfwkyY0mkZ8iF86DQ0LcnwIZOOEzwxnZTQBhjolEmgblPDhBrLjmIMDmDA+BL5VtlIlizt7fSDFkZgPedZ7+1dc/6/GY1W79l330fv6ujd3fNcRFVBRP60Jd0AIkoGk5/IKSY/kVNMfiKnmPxETjH5iZxi8hM5xeQncorJT+RUupkHa5cOzaK7mYc8LUh7xozne9vNeHbBZDCWK6bsx560j41YB9CUfYd5XRPB2LGJLnPf7N7w7wUAWiqZcY8mMY6cTkkl960p+UXkBgAPAUgB+JGqPmDdP4tuXCXX1XLI6knkfCTYzTl95nIzPnzTMjN+wRdfC8b2js2zH/uNRWa8LfJ3VOwtmvHVl/86GHtqaJW570V3h38vACiNjZnxmrTw34tls26s+L5Vv+wXkRSA7wO4EcDFAG4XkYurfTwiaq5a3vNfCWCXqr6lqjkAPwWwuj7NIqJGqyX5lwLYO+PnfeVtHyAia0VkUEQG85iq4XBEVE8N/7RfVdep6oCqDmTQ0ejDEVGFakn+/QBmflK1rLyNiE4DtST/FgArReQcEWkHcBuAp+vTLCJqtKpLfapaEJG7APwC06W+9ar6St1adqoaXJpJLzvp44z37fxruxT3x1dvNePz02+a8YO5w2Z8TjpcD//2Mvv/8TmX9pjxmOMluxb/zMSSYKxwqd0HYdELdilv5/EzzPjg/14QjF34D2+b+xYOHDTjHwU11flV9RkAz9SpLUTUROzeS+QUk5/IKSY/kVNMfiKnmPxETjH5iZySZq7YM1f6tGFDemus87d98mNm/OZHXwjGNr97jrnvsZw9bv1EITKePzImfzwXHu8/csyeP6Gr2x5vUSza14dczq4WZzLhIb9n9R019+1IF8x4T9pu+5xMuA/C4Um7f8OeDeeb8QUPv2jGk7JZN2JURyoaz88rP5FTTH4ip5j8RE4x+YmcYvITOcXkJ3KqqVN3N1SNJcuj386b8RePnReMvT3aZ+6bjZSsSmpXZqYipT6R8O8eK+VNTdl/AoVIKS9tlPIAYE5XuNwWK3FOFe1jj05lzXiqbU4w1p3Jmfue/xV75uDRJ+ab8eJRu4zZCnjlJ3KKyU/kFJOfyCkmP5FTTH4ip5j8RE4x+Ymc+ujU+SPS564w459YMGzG946HV7vtyth9BKYK9mnuy4aXsQaARZ12P4G0hJeqLmhkSG6klp4r2X0M5rWfMOP92XeDsamSXec/UYz0AyjZbT94Ilznj/URWJK1pw1/7Y5PmvHF3/+VGW8FvPITOcXkJ3KKyU/kFJOfyCkmP5FTTH4ip5j8RE7VVOcXkd0AxgAUARRUdaAejWqEwuK5ZvzqXrsu+1+li4KxuZEppM/sOGbGJ0rhqbcBoC89bsbzGq7Ftxl9AAAgI/Z4/FKkn0BHm93HIYXw8fNq//nF2h7rJwDjKR8as5dVn5u2+y9MXmv3A8D37XArqEcnn8+o6pE6PA4RNRFf9hM5VWvyK4BnRWSriKytR4OIqDlqfdl/jaruF5HFAJ4Tkd+q6qaZdyj/U1gLAFnYy1YRUfPUdOVX1f3l74cAPAngylnus05VB1R1IIOOWg5HRHVUdfKLSLeIzHnvNoDrAeyoV8OIqLFqedm/BMCTMr06bhrAv6jqz+vSKiJquKqTX1XfAmAPam4hhy+zl6rOil2v/oPeN4OxWK08I/Z4/CMFuw/CCyPhNQMA4Dd7wjXr1B573Hp63F4zIGV3YUBmPLL0uXFaix32sY993D5v3/jDZ834oVz4vF7Qfcjc96x2u3r9fJf9nJwOWOojcorJT+QUk5/IKSY/kVNMfiKnmPxETonWuLT1qZgrfXqVXNe0452K1MpzzfiuLy8Jxjo+Fp6eGgCW/p09/bVuedmM1yI11y4jypweM67dnWa8NNeOFzvDw27TY3YdsTT0qhmPueLX4SHB18+1+6PtL9hLcL8ysdSMb70smevqZt2IUR2xa6hlvPITOcXkJ3KKyU/kFJOfyCkmP5FTTH4ip5j8RE65WaL79X86aZKhD4p0d+j/n/AdZMiupefm20NTb9tpDy+1pr8GgDcnFwdjr47adfj9Y3adf6oQ6aOgdttEJoOxJXOOm/veuewdM/6zQ1eY8W1/Ee6bMfSuPSRXf3fQjJcm7GXVTwe88hM5xeQncorJT+QUk5/IKSY/kVNMfiKnmPxETrkZzz/+J1eZ8d99xt4/3ReuV39n4HFz33v+44tmvP95+zmY6rX/R48aJetCd+T5jYXT9h00Y8clFx5aLiV72Pm8nXa8fcw+9tFbwkubF/J2F5fSMXvZ9Hs/++9m/KnPXmrGC8MHzHi1OJ6fiKKY/EROMfmJnGLyEznF5CdyislP5BSTn8ipaJ1fRNYDuBnAIVW9pLytD8BjAFYA2A3gVlU9GjtYknV+aw53ADhe7DDjW48sD8YWdNpju6+Yt8eMf2tRbfPTHy+F+yCMlOy5BCbVLgkXI/EJtevlWWP58t42e2nzZWl7roFXcifM+DffuSUYe+PIQnPf7LP2HA35Hvu89D/4KzPeKPWu8/8YwA0f2nYvgI2quhLAxvLPRHQaiSa/qm4CMPKhzasBbCjf3gAg/C+WiFpSte/5l6jqcPn2AQDh+ZKIqCXV/IGfTn9oEPzgQETWisigiAzmYa/NRkTNU23yHxSRfgAofw/OQKmq61R1QFUHMrA/VCOi5qk2+Z8GsKZ8ew2Ap+rTHCJqlmjyi8ijAF4EcKGI7BOROwE8AODzIvIGgM+Vfyai04ib8fxv/f3vm/ErrnnNjN+2+KVg7K9e+lNz344d9tz5k4vsPgjd++z/0WpMrV+KrMxQ7IyM17en7Y+SQrjknLbL9GjL2/G83Q0Ak8tzwdiuG9eZ+355z7Vm/JGzN5nxz93xFTOe+uU2M14tjucnoigmP5FTTH4ip5j8RE4x+YmcYvITOeVmie7OC4+Z8aOTXWb8+dELgrHuLXYp78RV4SmkAeCPVtpDektq/4/uiNXEDPlILS927Daxy5RtEi4ldrTZw40LJfvY20bCw6wBYPRnZwZjf/upS8x9X9p7thn/xIE7zPjybbvMuD2YuTl45SdyislP5BSTn8gpJj+RU0x+IqeY/EROMfmJnHJT5//00rfMeGcqPPwTAG7o3R6MvXjgSnPf0RMZM36iaC8HvX+i14yn28K19qmC/RRnUnbFOVZr18jU3mLU+Rdm7f4PEwX7vH18nr3M9ZaJcJ3/nI7g5FMAgIvPsB/7vJ4jZnzHigvNOLaP2vEm4JWfyCkmP5FTTH4ip5j8RE4x+YmcYvITOcXkJ3LKTZ0/HVkOeiTXbcYnNVxzbh+1HzvTaY+3L0TGzLdH2t6eCo+LbwuvpAYgfl4KYo/3j43nLxjzBWQix+7J2I8dm8eg67A9X4DlojkH7ceO9AuZOMte4jsb7jbSNLzyEznF5CdyislP5BSTn8gpJj+RU0x+IqeY/ERORev8IrIewM0ADqnqJeVt9wP4KoDD5bvdp6rPNKqR9ZARu6ZszS8PAHkNn6qOI5PmvtlOu96cL9m19FgtvhQZU1/LviXY8djV44QxJj+fsX/vzpRdx7fmMQCA7L6xYOxIwa7DT0XWNo+tOZCba5+ZrBltjkqu/D8GcMMs27+nqqvKXy2d+ER0smjyq+omACNNaAsRNVEt7/nvEpHtIrJeRObXrUVE1BTVJv8PAJwHYBWAYQAPhu4oImtFZFBEBvOYqvJwRFRvVSW/qh5U1aKqlgD8EEBwBktVXaeqA6o6kEFHte0kojqrKvlFpH/Gj18AsKM+zSGiZqmk1PcogGsBLBSRfQC+BeBaEVkFQAHsBvC1BraRiBogmvyqevssmx9uQFsSFa3bGuPS03vsOeDnZO25Ampl9VGIzRWQjfQhSEdWko/V2lPGeP9cpH9D7DmJkcnwZ0yxeQhiv1esH0ApVX3fi2ZhDz8ip5j8RE4x+YmcYvITOcXkJ3KKyU/klJupu2sZ9goAKWMK7MIBe5rnbPosMx5rWyFSErPKVlNF+ylOR0pesSG9pWL114/Jor0Ed6xtKdhx7Q4PnH194gxz33npCTMeU2yFMbsRvPITOcXkJ3KKyU/kFJOfyCkmP5FTTH4ip5j8RE65qfMnqbf9hBmPDbutZfipNaS2EtH+EZFw0fjdSmq37XjBnvkptsR3sbs9GPvlO+eb+95xwaAZf7fQacZr7FbSFLzyEznF5CdyislP5BSTn8gpJj+RU0x+IqeY/EROuanz7z1hLyd4RnbUjGek+mmkF3TYY8PHIvXsUqQfQKGGUn50Ce7I0uVtxjwHgF2Lj/UhsJb3ruTY2hZ+/Kl9Pea+XRflzPhR7bKPbU/B0BJ45SdyislP5BSTn8gpJj+RU0x+IqeY/EROMfmJnIrW+UVkOYBHACwBoADWqepDItIH4DEAKwDsBnCrqh5tXFNtbVl7ovRYTTkj9tjwXVP2PO+W7nR4qWgAGC+Ex51XwuoH0JW269W5yFLTsTp/TDaVr/rYxZJ9bYr1UdBMeP/uPfZj96QmzfhUye6DUMq0/oD+Sq78BQD3qOrFAH4PwNdF5GIA9wLYqKorAWws/0xEp4lo8qvqsKpuK98eA7ATwFIAqwFsKN9tA4BbGtVIIqq/U3rPLyIrAFwGYDOAJao6XA4dwPTbAiI6TVSc/CLSA+BxAHer6gc6wquqArN3tBaRtSIyKCKDedjvfYmoeSpKfhHJYDrxf6KqT5Q3HxSR/nK8H8Ch2fZV1XWqOqCqAxnYA1iIqHmiyS8iAuBhADtV9bszQk8DWFO+vQbAU/VvHhE1SiVDeq8G8CUAL4vIUHnbfQAeAPCvInIngHcA3NqYJlZm+p1HWKzU12mUpABg0/+tNKL2Et0dbfZw4FjJKja1t6WtwUN2Y20rGEuEW1OOA/HnbDJSbsv1ho/d95r9fHe32W9Ro2XG1q/0xZNfVV9AeHb26+rbHCJqFvbwI3KKyU/kFJOfyCkmP5FTTH4ip5j8RE65mbo7Nv11bEjvbw8uDsbOjtT5Y48dq2fHhuWmjWW4O1J2H4N8qbY5pmPLh1vnPRc5dq3DiSd7w4+/YOiYuW9sqvZY/4fY0uWtgFd+IqeY/EROMfmJnGLyEznF5CdyislP5BSTn8gpP3X+SOE1VovP7+uu+tjH8vZyzrtGFprxseOdZrxUrL6orMXI//82u54tsVq80TSJNDvTbtfa57XbS5/ne4wD7Npj7puK1PHzkX4jkVnJWwKv/EROMfmJnGLyEznF5CdyislP5BSTn8gpJj+RU6dBNbIyEikaR8dfR2SOV19Ln5ex69Fd7fYc8rms/TQtmxcemz5lzJsPALmiPaa+1mHp1pj8VGTe/iPH7b4V/dlRM775jPCxS+Pj5r7zUnY8ts5DZEmBlsArP5FTTH4ip5j8RE4x+YmcYvITOcXkJ3KKyU/kVLTOLyLLATwCYAkABbBOVR8SkfsBfBXA4fJd71PVZxrV0KiMXVgdL7Sb8YmSHa9lvfXHfn6NGS/MtecS6Dhi1+LfTs0NxiLTFERpZFr/6HmxxvPbZX5IwX7wfxu93Iwv21r9Lz9e6jDjuciA/chw/5ZQSSefAoB7VHWbiMwBsFVEnivHvqeq/9i45hFRo0STX1WHAQyXb4+JyE4ASxvdMCJqrFN6cSIiKwBcBmBzedNdIrJdRNaLyPzAPmtFZFBEBvOYqqmxRFQ/FSe/iPQAeBzA3ao6CuAHAM4DsArTrwwenG0/VV2nqgOqOpCB/T6KiJqnouQXkQymE/8nqvoEAKjqQVUtqmoJwA8BXNm4ZhJRvUWTX6aHyz0MYKeqfnfG9v4Zd/sCgB31bx4RNUoln/ZfDeBLAF4WkaHytvsA3C4iqzBd/tsN4GsNaWGF2nrs4Z+pSF0pOnV3b6QuZTj33her3peSUYpcF2NDxPO9tQ0hb4ZKPu1/AbNXa5Or6RNRzU6DrghE1AhMfiKnmPxETjH5iZxi8hM5xeQncuojM3V3YfiAGX/9zU+Z8V3Di834oi01/J+MrUUdo61fM/6o+ctf/JkZn3/2UTO+cKj1nzNe+YmcYvITOcXkJ3KKyU/kFJOfyCkmP5FTTH4ip0SbWEMWkcMA3pmxaSGAI01rwKlp1ba1arsAtq1a9Wzb2aq6qJI7NjX5Tzq4yKCqDiTWAEOrtq1V2wWwbdVKqm182U/kFJOfyKmkk39dwse3tGrbWrVdANtWrUTaluh7fiJKTtJXfiJKSCLJLyI3iMhrIrJLRO5Nog0hIrJbRF4WkSERGUy4LetF5JCI7JixrU9EnhORN8rfZ10mLaG23S8i+8vnbkhEbkqobctF5L9F5FUReUVEvlHenui5M9qVyHlr+st+EUkBeB3A5wHsA7AFwO2q+mpTGxIgIrsBDKhq4jVhEfk0gOMAHlHVS8rbvgNgRFUfKP/jnK+qf9MibbsfwPGkV24uLyjTP3NlaQC3APhzJHjujHbdigTOWxJX/isB7FLVt1Q1B+CnAFYn0I6Wp6qbAIx8aPNqABvKtzdg+o+n6QJtawmqOqyq28q3xwC8t7J0oufOaFcikkj+pQD2zvh5H1pryW8F8KyIbBWRtUk3ZhZLysumA8ABAEuSbMwsois3N9OHVpZumXNXzYrX9cYP/E52japeDuBGAF8vv7xtSTr9nq2VyjUVrdzcLLOsLP2+JM9dtSte11sSyb8fwPIZPy8rb2sJqrq//P0QgCfReqsPH3xvkdTy90MJt+d9rbRy82wrS6MFzl0rrXidRPJvAbBSRM4RkXYAtwF4OoF2nEREussfxEBEugFcj9ZbffhpAGvKt9cAeCrBtnxAq6zcHFpZGgmfu5Zb8VpVm/4F4CZMf+L/JoBvJtGGQLvOBfCb8tcrSbcNwKOYfhmYx/RnI3cCWABgI4A3APwngL4Wats/A3gZwHZMJ1p/Qm27BtMv6bcDGCp/3ZT0uTPalch5Yw8/Iqf4gR+RU0x+IqeY/EROMfmJnGLyEznF5CdyislP5BSTn8ip/weo6I3WBznWugAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the number of training and test datasets\n",
    "print(x_train.shape[0], 'train set')\n",
    "print(x_test.shape[0], 'test set')\n",
    "\n",
    "# Define the text labels\n",
    "fashion_mnist_labels = [\"T-shirt/top\",  # index 0\n",
    "                        \"Trouser\",      # index 1\n",
    "                        \"Pullover\",     # index 2 \n",
    "                        \"Dress\",        # index 3 \n",
    "                        \"Coat\",         # index 4\n",
    "                        \"Sandal\",       # index 5\n",
    "                        \"Shirt\",        # index 6 \n",
    "                        \"Sneaker\",      # index 7 \n",
    "                        \"Bag\",          # index 8 \n",
    "                        \"Ankle boot\"]   # index 9\n",
    "\n",
    "# Image index, you can pick any number between 0 and 59,999\n",
    "img_index = 5\n",
    "\n",
    "# y_train contains the lables, ranging from 0 to 9\n",
    "label_index = y_train[img_index]\n",
    "\n",
    "# Print the label, for example 2 Pullover\n",
    "print (\"y = \" + str(label_index) + \" \" +(fashion_mnist_labels[label_index]))\n",
    "\n",
    "# Show one of the images from the training dataset\n",
    "plt.imshow(x_train[img_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator(images, reuse_variables=None):\n",
    "    with tf.variable_scope(tf.get_variable_scope(), reuse=reuse_variables) as scope:\n",
    "        \n",
    "        # First convolutional and pool layers\n",
    "        # This finds 32 different 5 x 5 pixel features\n",
    "        filter1 = tf.get_variable('d_f1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias1   = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "        output1 = tf.nn.conv2d(input=images, filter=filter1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        output1 = output1 + bias1\n",
    "        output1 = tf.nn.relu(output1)\n",
    "        output1 = tf.nn.avg_pool(output1, ksize=[1, 2, 2, 1], strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "        # Second convolutional and pool layers\n",
    "        # This finds 64 different 5 x 5 pixel features\n",
    "        filter2 = tf.get_variable('d_f2', [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias2   = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "        output2 = tf.nn.conv2d(input=output1, filter=filter2, strides=[1,1,1,1], padding='SAME')\n",
    "        output2 = output2 + bias2\n",
    "        output2 = tf.nn.relu(output2)\n",
    "        output2 = tf.nn.avg_pool(output2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "        \n",
    "        # First fully connected layer\n",
    "        weight3 = tf.get_variable('d_w3', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias3   = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "        output3 = tf.reshape(output2, [-1, 7*7*64])\n",
    "        output3 = tf.matmul(output3, weight3) + bias3\n",
    "        output3 = tf.nn.relu(output3)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        weight4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "        bias4   = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "        output4 = tf.matmul(output3, weight4) + bias4\n",
    "        \n",
    "        # output4 contains unscaled values\n",
    "        return output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    # From z_dim to 56*56 dimension\n",
    "    weight1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    bias1   = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    output1 = tf.matmul(z, weight1) + bias1\n",
    "    output1 = tf.reshape(output1, [-1, 56, 56, 1])\n",
    "    output1 = tf.contrib.layers.batch_norm(output1, epsilon=1e-5, scope='bn1')\n",
    "    output1 = tf.nn.relu(output1)\n",
    "    \n",
    "    # Generate 50 features\n",
    "    weight2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    bias2   = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    output2 = tf.nn.conv2d(output1, weight2, strides=[1,2,2,1], padding='SAME')\n",
    "    output2 = output2 + bias2\n",
    "    output2 = tf.contrib.layers.batch_norm(output2, epsilon=1e-5, scope='bn2')\n",
    "    output2 = tf.nn.relu(output2)\n",
    "    output2 = tf.image.resize_images(output2, [56,56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    weight3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    bias3   = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    output3 = tf.nn.conv2d(output2, weight3, strides=[1,2,2,1], padding='SAME')\n",
    "    output3 = output3 + bias3\n",
    "    output3 = tf.contrib.layers.batch_norm(output3, epsilon=1e-5, scope='bn3')\n",
    "    output3 = tf.nn.relu(output3)\n",
    "    output3 = tf.image.resize_images(output3, [56, 56])\n",
    "    \n",
    "    # Final convolution with one output channel\n",
    "    weight4 = tf.get_variable('g_w4', [1,1,z_dim/4,1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    bias4   = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    output4 = tf.nn.conv2d(output3, weight4, strides=[1,2,2,1], padding='SAME')\n",
    "    output4 = output4 + bias4\n",
    "    output4 = tf.sigmoid(output4)\n",
    "    \n",
    "    # Dimension of output4: batch_size x 28 x 28 x 2\n",
    "    return output4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" See the fake image we make \"\"\"\n",
    "\n",
    "# Define the plaaceholder and the graph\n",
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])\n",
    "\n",
    "# For generator, one image for a batch\n",
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0, 1, [1, z_dimensions])\n",
    "\n",
    "with tf.Session() as sess:    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output, feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28, 28])\n",
    "    plt.imshow(generated_image, cmap='Greys')\n",
    "#     plt.savefig('/img/test_img.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128 # should be 2^n\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder')\n",
    "# z_placeholder is for feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, [None, 28, 28, 1], name='x_placeholder')\n",
    "# x_placeholder is for feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
    "# Gz holds the generated images\n",
    "\n",
    "Dx = discriminator(x_placeholder)\n",
    "# Dx will hold discriminator prediction probabilities for the real MNIST images\n",
    "\n",
    "Dg = discriminator(Gz, reuse_variables=True)\n",
    "# Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two Loss Functions for discirminator\n",
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))\n",
    "\n",
    "# Loss function for generator\n",
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variables for different network\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "# Train the discirminator\n",
    "d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" For setting TensorBoard \"\"\"\n",
    "\n",
    "# From this point forward, reuse variables\n",
    "tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "tf.summary.scalar('Generator_loss', g_loss)\n",
    "tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLossReal: 0.0993647 dLossFake: 0.6836779\n",
      "dLossReal: 0.0 dLossFake: 9.750632e-06\n",
      "dLossReal: 6.95669e-35 dLossFake: 4.399728e-06\n",
      "dLossReal: 3.8271688e-17 dLossFake: 3.361105e-06\n",
      "dLossReal: 5.7649045e-15 dLossFake: 2.5053541e-06\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Start Training Session \"\"\"\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Pre-train discriminator\n",
    "for i in range(500):\n",
    "    \n",
    "    for j in range(1500//batch_size):\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "        # real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28, 28, 1])\n",
    "    \n",
    "        real_image_batch = x_train[j*batch_size:(j+1)*batch_size].reshape([batch_size, 28, 28, 1])\n",
    "        _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                               {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "    if(i % 100 == 0):\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLossReal: 0.026286315 dLossFake: 0.014274681\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-43e506faa871>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Train generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mz_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_trainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train generator and discriminator together\n",
    "for i in range(300):\n",
    "    for j in range(60000//batch_size):\n",
    "        real_image_batch = x_train[j*batch_size:(j+1)*batch_size].reshape([batch_size, 28, 28, 1])\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "        # Train discriminator on both real and fake images\n",
    "        _, __, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake],\n",
    "                                               {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "        # Train generator\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "        _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "    if(i % 100 == 0):\n",
    "        print(\"dLossReal:\", dLossReal, \"dLossFake:\", dLossFake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "_ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1f14e04860>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "generated_image = sess.run(Gz, feed_dict={z_placeholder: z_batch})\n",
    "generated_image = generated_image.reshape([batch_size, 28, 28])\n",
    "plt.imshow(generated_image[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
